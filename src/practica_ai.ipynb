{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practica Numero 1\n",
    "# 1.1 Random Forest\n",
    "# 1.2 Gradient Boosting Machine\n",
    "\n",
    "# Desarrollar un marco teorico y practico para cada uno de los casos, usando el dataset de EMNIST. \n",
    "# Debe incluir una conclusion de valoracion de casos de uso y tiempo de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports required\n",
    "import os\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from mainHelper import emnistHelper\n",
    "from mainHelper import DataLoader as dl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#Config from .env variable\n",
    "dotenv_path = '.env'\n",
    "load_dotenv(dotenv_path)\n",
    "#Get variables\n",
    "SERVER = os.environ['SQL_SERVER']\n",
    "DATABASE = os.environ['DATABASE']\n",
    "UID = os.environ['UID']\n",
    "PWD = os.environ['PWD']\n",
    "RUN_HELPER = os.environ['RUN_HELPER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to the database\n",
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      f'Server={SERVER};'\n",
    "                      f'Database={DATABASE};'\n",
    "                      f'UID={UID};'\n",
    "                      f'PWD={PWD};')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if table Letters exists\n",
    "if not cursor.tables(table='Letters', tableType='TABLE').fetchone():\n",
    "    # Create a table for letters\n",
    "    cursor.execute(\"CREATE TABLE Letters ( a0 int )\")\n",
    "    conn.commit()\n",
    "    for i in range(1,785):\n",
    "        cursor.execute(f'''\n",
    "                        ALTER TABLE Letters\n",
    "                        ADD a{i} int;\n",
    "                    ''')\n",
    "        conn.commit()\n",
    "\n",
    "        \n",
    "# Check if table Digits exists\n",
    "if not cursor.tables(table='Digits', tableType='TABLE').fetchone():\n",
    "    # Create a table for Digits\n",
    "    cursor.execute(\"CREATE TABLE Digits ( a0 int )\")\n",
    "    conn.commit()\n",
    "    for i in range(1,785):\n",
    "        cursor.execute(f'''\n",
    "                        ALTER TABLE Digits\n",
    "                        ADD a{i} int;\n",
    "                    ''')\n",
    "        conn.commit()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RUN_HELPER)\n",
    "if RUN_HELPER:\n",
    "    emnistHelper.emnist_to_sql(cursor, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DougC\\OneDrive\\Escritorio\\Andres\\src\\mainHelper\\DataLoader.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql_query(f'SELECT * FROM {table}', conn)\n",
      "c:\\Users\\DougC\\OneDrive\\Escritorio\\Andres\\src\\mainHelper\\DataLoader.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql_query(f'SELECT * FROM {table}', conn)\n"
     ]
    }
   ],
   "source": [
    "loader = dl.Data()\n",
    "digits = loader.loadData('Digits', conn)\n",
    "letters = loader.loadData('Letters', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get x and y from data\n",
    "#Digits\n",
    "x_digits = loader.getX(digits)\n",
    "y_digits = loader.getY(digits)\n",
    "#Letters\n",
    "x_letters = loader.getX(letters)\n",
    "y_letters = loader.getY(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First digits\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_digits, y_digits, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second letters\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_letters, y_letters, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the data to improve classification performance\n",
    "binarizer = Binarizer(threshold=0.707)\n",
    "x_train_bin = binarizer.fit_transform(x_train)\n",
    "x_test_bin = binarizer.transform(x_test)\n",
    "\n",
    "# Perform PCA to reduce the dimensionality of the data\n",
    "pca = PCA(n_components=0.95)\n",
    "x_train_pca = pca.fit_transform(x_train_bin)\n",
    "x_test_pca = pca.transform(x_test_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum label in y_train: 0\n",
      "Maximum label in y_train: 51\n",
      "Minimum label in y_test: 0\n",
      "Maximum label in y_test: 51\n"
     ]
    }
   ],
   "source": [
    "# Check the range of labels in y_train\n",
    "print(f\"Minimum label in y_train: {np.amin(y_train)}\")\n",
    "print(f\"Maximum label in y_train: {np.amax(y_train)}\")\n",
    "print(f\"Minimum label in y_test: {np.amin(y_test)}\")\n",
    "print(f\"Maximum label in y_test: {np.amax(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40 30 43 ... 34  8 18]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just for letters:\n",
    "# Subtract 10 from the labels in y_train and y_test\n",
    "y_train -= 10\n",
    "y_test -= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators=10, accuracy=0.5178800034138431\n",
      "n_estimators=50, accuracy=0.6486301954425194\n",
      "n_estimators=100, accuracy=0.6709055218912691\n",
      "n_estimators=150, accuracy=0.6748314414952633\n",
      "n_estimators=200, accuracy=0.6777332081590851\n"
     ]
    }
   ],
   "source": [
    "# Try different values for n_estimators and evaluate performance\n",
    "n_estimators_list = [10, 50, 100, 150, 200]\n",
    "for n_estimators in n_estimators_list:\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    rf.fit(x_train_pca, y_train)\n",
    "    accuracy = rf.score(x_test_pca, y_test)\n",
    "    print(f\"n_estimators={n_estimators}, accuracy={accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state=42, accuracy=0.6709055218912691\n",
      "random_state=123, accuracy=0.6676623709140564\n",
      "random_state=456, accuracy=0.6699667150294444\n",
      "random_state=789, accuracy=0.6673209866006657\n",
      "random_state=999, accuracy=0.6668942562089272\n"
     ]
    }
   ],
   "source": [
    "# Try different values for random_state and evaluate performance\n",
    "random_state_list = [42, 123, 456, 789, 999]\n",
    "for random_state in random_state_list:\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "    rf.fit(x_train_pca, y_train)\n",
    "    accuracy = rf.score(x_test_pca, y_test)\n",
    "    print(f\"random_state={random_state}, accuracy={accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_rounds=10, accuracy=0.6363559322033898\n",
      "num_rounds=50, accuracy=0.7027118644067797\n",
      "num_rounds=100, accuracy=0.7242372881355932\n"
     ]
    }
   ],
   "source": [
    "#Now we will check the GBM\n",
    "import xgboost as xgb\n",
    "\n",
    "# Convert the data to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(x_train_pca, label=y_train)\n",
    "dtest = xgb.DMatrix(x_test_pca, label=y_test)\n",
    "\n",
    "# Define the hyperparameters for the XGBoost model\n",
    "params = {'objective': 'multi:softmax',\n",
    "          'num_class': len(set(y_train)),\n",
    "          'eval_metric': 'merror',\n",
    "          'max_depth': 5,\n",
    "          'eta': 0.1,\n",
    "          'subsample': 0.8,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'seed': 42}\n",
    "\n",
    "# Try different values for num_rounds and evaluate performance\n",
    "num_rounds_list = [10, 50, 100, 150, 200]\n",
    "for num_rounds in num_rounds_list:\n",
    "    # Train the XGBoost model\n",
    "    xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "    # Make predictions on the test data using the trained model\n",
    "    preds = xgb_model.predict(dtest)\n",
    "\n",
    "    # Evaluate the performance of the XGBoost model on the test data\n",
    "    accuracy = sum(y_test == preds) / len(y_test)\n",
    "    print(f\"num_rounds={num_rounds}, accuracy={accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " rescaling_1 (Rescaling)     (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 52)                6708      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 123,700\n",
      "Trainable params: 123,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784))\n",
    "x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(52, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit on NumPy data\n",
      "Epoch 1/20\n",
      "738/738 [==============================] - 6s 4ms/step - loss: 1.3336 - acc: 0.6348\n",
      "Epoch 2/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.7975 - acc: 0.7587\n",
      "Epoch 3/20\n",
      "738/738 [==============================] - 3s 5ms/step - loss: 0.6714 - acc: 0.7890\n",
      "Epoch 4/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.6029 - acc: 0.8032\n",
      "Epoch 5/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.5532 - acc: 0.8163\n",
      "Epoch 6/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.5172 - acc: 0.8240\n",
      "Epoch 7/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.4826 - acc: 0.8340\n",
      "Epoch 8/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.4585 - acc: 0.8388\n",
      "Epoch 9/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.4353 - acc: 0.8450\n",
      "Epoch 10/20\n",
      "738/738 [==============================] - 3s 5ms/step - loss: 0.4156 - acc: 0.8504\n",
      "Epoch 11/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.3958 - acc: 0.8574\n",
      "Epoch 12/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.3785 - acc: 0.8622\n",
      "Epoch 13/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.3646 - acc: 0.8644\n",
      "Epoch 14/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.3490 - acc: 0.8696\n",
      "Epoch 15/20\n",
      "738/738 [==============================] - 4s 5ms/step - loss: 0.3340 - acc: 0.8751\n",
      "Epoch 16/20\n",
      "738/738 [==============================] - 3s 5ms/step - loss: 0.3215 - acc: 0.8791\n",
      "Epoch 17/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.3076 - acc: 0.8823\n",
      "Epoch 18/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.2983 - acc: 0.8863\n",
      "Epoch 19/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.2878 - acc: 0.8889\n",
      "Epoch 20/20\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 0.2786 - acc: 0.8925\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "# Train the model for 1 epoch from Numpy data\n",
    "batch_size = 64\n",
    "print(\"Fit on NumPy data\")\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
